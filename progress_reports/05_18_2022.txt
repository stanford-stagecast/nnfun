During hackathon:
- Makeing learning_rate a field variable -> dynamic learning rate.
- Input array instead of hand-input layers (specifially rest).
- Discussed some project ideas.
- Tested abstraction with linear predictor, success.
- Tested abstraction with 1/x, nan. Probably dynamic learning rate is needed.

After hackathon:
Jamie will work on dynamic learning rate.

[Update on 05_21]:
Dynamic learnign rate is added to the nn.
Current status:
The new abstraction works with linear predictors.
The new abstraction is able to predict 1/x in range [1,20] if training on random
float values in range [1,20] with 100000 iterations.
